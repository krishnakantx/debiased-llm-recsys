# Mistral 7B config

dataset: movielens

model_name: "mistralai/Mistral-7B-v0.1"
max_seq_length: 512

lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj

sft:
  learning_rate: 2.0e-5
  num_epochs: 3
  batch_size: 4
  gradient_accumulation_steps: 8
  warmup_ratio: 0.1
  weight_decay: 0.01
  output_dir: "./outputs/mistral_sft"
  logging_steps: 10
  save_steps: 200

dpo:
  beta: 0.1
  learning_rate: 5.0e-6
  num_epochs: 1
  batch_size: 2
  gradient_accumulation_steps: 8
  warmup_ratio: 0.1
  weight_decay: 0.01
  output_dir: "./outputs/mistral_dpo"
  logging_steps: 10
  save_steps: 200

evaluation:
  k: 5

device: cuda
